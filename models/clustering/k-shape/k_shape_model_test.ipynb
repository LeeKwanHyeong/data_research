{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-19T22:31:57.045174Z",
     "start_time": "2025-08-19T22:31:55.547063Z"
    }
   },
   "source": [
    "import polars as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from kshape_core_gpu import KShapeClusteringGPU\n",
    "import sys\n",
    "\n",
    "MAC_DIR = '/Users/igwanhyeong/PycharmProjects/data_research/data/'\n",
    "WINDOW_DIR = 'C:/Users/USER/PycharmProjects/research/data/'\n",
    "\n",
    "if sys.platform == 'win32':\n",
    "    DIR = WINDOW_DIR\n",
    "    print(torch.cuda.is_available())\n",
    "    print(torch.cuda.device_count())\n",
    "    print(torch.version.cuda)\n",
    "    print(torch.__version__)\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print(torch.__version__)\n",
    "else:\n",
    "    DIR = MAC_DIR\n",
    "\n",
    "tb_bas_oper_part_mst = (pl.read_parquet(DIR + 'tb_bas_oper_part_mst.parquet')\n",
    "                        .select(['OPER_PART_NO', 'OPER_PART_NM'])\n",
    "                        .rename({'OPER_PART_NO': 'oper_part_no', 'OPER_PART_NM': 'oper_part_nm'}))\n",
    "tb_dyn_fcst_demand_sellout = (pl.read_parquet(DIR + 'tb_dyn_fcst_dmnd_sellout.parquet')\n",
    "                              .select(['PART_NO', 'DMND_QTY', 'DMND_DT', 'OPER_PART_NO'])\n",
    "                              .rename({'PART_NO': 'part_no', 'OPER_PART_NO': 'oper_part_no', 'DMND_DT': 'demand_dt', 'DMND_QTY': 'demand_qty'})\n",
    "                              .select(['part_no', 'oper_part_no', 'demand_dt', 'demand_qty']))"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T22:31:57.710116Z",
     "start_time": "2025-08-19T22:31:57.047904Z"
    }
   },
   "cell_type": "code",
   "source": [
    "target_df = (tb_dyn_fcst_demand_sellout\n",
    "    .with_columns(\n",
    "        (pl.col(\"demand_dt\").cast(pl.Int64) // 100).alias(\"demand_yyyymm\")\n",
    "    )\n",
    "    .join(tb_bas_oper_part_mst, on = 'oper_part_no', how = 'left')\n",
    "    .group_by(['oper_part_no', 'demand_yyyymm'])\n",
    "    .agg(pl.col('demand_qty').sum().alias('demand_qty'))\n",
    "    .sort(['oper_part_no', 'demand_yyyymm'])\n",
    "    .with_columns(pl.col('demand_yyyymm').cast(pl.Utf8).str.strptime(pl.Date, '%Y%m').alias('month'))\n",
    ")\n",
    "\n",
    "\n",
    "min_month = target_df.select(pl.col('month').min())[0, 0]\n",
    "max_month = target_df.select(pl.col('month').max())[0, 0]\n",
    "\n",
    "full_months = pl.date_range(start = min_month, end = max_month, interval = '1mo', eager = True)\n",
    "month_df = pl.DataFrame({'month': full_months})\n",
    "unique_parts = target_df.select(pl.col('oper_part_no').unique())\n",
    "base = unique_parts.join(month_df, how = 'cross')\n",
    "\n",
    "aligned_df = (base\n",
    "                .join(\n",
    "                    target_df.select(['oper_part_no', 'month', 'demand_qty']),\n",
    "                    on = ['oper_part_no', 'month'], how = 'left')\n",
    "                .with_columns(pl.col('demand_qty').fill_null(0.0))\n",
    "                .pivot(\n",
    "                    values = 'demand_qty',\n",
    "                    on = 'month',\n",
    "                    aggregate_function = 'first'\n",
    "                )\n",
    "              )"
   ],
   "id": "bd10376dc50e3d27",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T22:31:57.718621Z",
     "start_time": "2025-08-19T22:31:57.713862Z"
    }
   },
   "cell_type": "code",
   "source": "aligned_df",
   "id": "422895f208517968",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "shape: (43_896, 112)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ oper_part ┆ 2017-12-0 ┆ 2018-01-0 ┆ 2018-02-0 ┆ … ┆ 2026-11-0 ┆ 2026-12-0 ┆ 2027-01-0 ┆ 2027-02- │\n",
       "│ _no       ┆ 1         ┆ 1         ┆ 1         ┆   ┆ 1         ┆ 1         ┆ 1         ┆ 01       │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---      │\n",
       "│ str       ┆ f64       ┆ f64       ┆ f64       ┆   ┆ f64       ┆ f64       ┆ f64       ┆ f64      │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ T4520-430 ┆ 0.0       ┆ 50.0      ┆ 17.0      ┆ … ┆ 7.0       ┆ 133.0     ┆ 0.0       ┆ 0.0      │\n",
       "│ 21        ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 53450-635 ┆ 0.0       ┆ 0.0       ┆ 0.0       ┆ … ┆ 0.0       ┆ 0.0       ┆ 0.0       ┆ 0.0      │\n",
       "│ 1-1       ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 9967999   ┆ 0.0       ┆ 1.0       ┆ 0.0       ┆ … ┆ 0.0       ┆ 0.0       ┆ 0.0       ┆ 0.0      │\n",
       "│ 350058000 ┆ 0.0       ┆ 0.0       ┆ 0.0       ┆ … ┆ 0.0       ┆ 0.0       ┆ 0.0       ┆ 0.0      │\n",
       "│ FTF31-118 ┆ 0.0       ┆ 0.0       ┆ 0.0       ┆ … ┆ 0.0       ┆ 0.0       ┆ 0.0       ┆ 0.0      │\n",
       "│ 2B        ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ …         ┆ …         ┆ …         ┆ …         ┆ … ┆ …         ┆ …         ┆ …         ┆ …        │\n",
       "│ 08101-063 ┆ 0.0       ┆ 190.0     ┆ 50.0      ┆ … ┆ 145.0     ┆ 68.0      ┆ 80.0      ┆ 0.0      │\n",
       "│ 05        ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ T4930-806 ┆ 0.0       ┆ 1.0       ┆ 0.0       ┆ … ┆ 1.0       ┆ 0.0       ┆ 0.0       ┆ 0.0      │\n",
       "│ 51        ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ CE11-0319 ┆ 0.0       ┆ 0.0       ┆ 0.0       ┆ … ┆ 0.0       ┆ 0.0       ┆ 0.0       ┆ 0.0      │\n",
       "│ A         ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ T4682-553 ┆ 0.0       ┆ 0.0       ┆ 0.0       ┆ … ┆ 0.0       ┆ 0.0       ┆ 0.0       ┆ 0.0      │\n",
       "│ 93        ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3161C017  ┆ 0.0       ┆ 0.0       ┆ 0.0       ┆ … ┆ 0.0       ┆ 0.0       ┆ 0.0       ┆ 0.0      │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ],
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (43_896, 112)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>oper_part_no</th><th>2017-12-01</th><th>2018-01-01</th><th>2018-02-01</th><th>2018-03-01</th><th>2018-04-01</th><th>2018-05-01</th><th>2018-06-01</th><th>2018-07-01</th><th>2018-08-01</th><th>2018-09-01</th><th>2018-10-01</th><th>2018-11-01</th><th>2018-12-01</th><th>2019-01-01</th><th>2019-02-01</th><th>2019-03-01</th><th>2019-04-01</th><th>2019-05-01</th><th>2019-06-01</th><th>2019-07-01</th><th>2019-08-01</th><th>2019-09-01</th><th>2019-10-01</th><th>2019-11-01</th><th>2019-12-01</th><th>2020-01-01</th><th>2020-02-01</th><th>2020-03-01</th><th>2020-04-01</th><th>2020-05-01</th><th>2020-06-01</th><th>2020-07-01</th><th>2020-08-01</th><th>2020-09-01</th><th>2020-10-01</th><th>2020-11-01</th><th>&hellip;</th><th>2024-02-01</th><th>2024-03-01</th><th>2024-04-01</th><th>2024-05-01</th><th>2024-06-01</th><th>2024-07-01</th><th>2024-08-01</th><th>2024-09-01</th><th>2024-10-01</th><th>2024-11-01</th><th>2024-12-01</th><th>2025-01-01</th><th>2025-02-01</th><th>2025-03-01</th><th>2025-04-01</th><th>2025-05-01</th><th>2025-06-01</th><th>2025-07-01</th><th>2025-08-01</th><th>2025-09-01</th><th>2025-10-01</th><th>2025-11-01</th><th>2025-12-01</th><th>2026-01-01</th><th>2026-02-01</th><th>2026-03-01</th><th>2026-04-01</th><th>2026-05-01</th><th>2026-06-01</th><th>2026-07-01</th><th>2026-08-01</th><th>2026-09-01</th><th>2026-10-01</th><th>2026-11-01</th><th>2026-12-01</th><th>2027-01-01</th><th>2027-02-01</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>&hellip;</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;T4520-43021&quot;</td><td>0.0</td><td>50.0</td><td>17.0</td><td>12.0</td><td>15.0</td><td>10.0</td><td>35.0</td><td>0.0</td><td>5.0</td><td>55.0</td><td>80.0</td><td>2.0</td><td>21.0</td><td>15.0</td><td>110.0</td><td>6.0</td><td>45.0</td><td>0.0</td><td>36.0</td><td>14.0</td><td>25.0</td><td>5.0</td><td>5.0</td><td>20.0</td><td>5.0</td><td>78.0</td><td>3.0</td><td>0.0</td><td>5.0</td><td>0.0</td><td>2.0</td><td>65.0</td><td>23.0</td><td>8.0</td><td>0.0</td><td>2.0</td><td>&hellip;</td><td>0.0</td><td>50.0</td><td>64.0</td><td>0.0</td><td>0.0</td><td>18.0</td><td>5.0</td><td>88.0</td><td>7.0</td><td>5.0</td><td>0.0</td><td>10.0</td><td>15.0</td><td>82.0</td><td>24.0</td><td>21.0</td><td>86.0</td><td>12.0</td><td>0.0</td><td>10.0</td><td>30.0</td><td>90.0</td><td>10.0</td><td>10.0</td><td>20.0</td><td>15.0</td><td>35.0</td><td>104.0</td><td>45.0</td><td>15.0</td><td>44.0</td><td>62.0</td><td>5.0</td><td>7.0</td><td>133.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;53450-6351-1&quot;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>3.0</td><td>6.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>9.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>2.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>&hellip;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>2.0</td><td>3.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>1.0</td><td>3.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;9967999&quot;</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>&hellip;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;350058000&quot;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>2.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>2.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>&hellip;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>2.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>5.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;FTF31-1182B&quot;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>&hellip;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;08101-06305&quot;</td><td>0.0</td><td>190.0</td><td>50.0</td><td>141.0</td><td>0.0</td><td>0.0</td><td>645.0</td><td>230.0</td><td>375.0</td><td>875.0</td><td>180.0</td><td>10.0</td><td>75.0</td><td>90.0</td><td>30.0</td><td>85.0</td><td>83.0</td><td>6.0</td><td>795.0</td><td>144.0</td><td>97.0</td><td>824.0</td><td>141.0</td><td>10.0</td><td>123.0</td><td>280.0</td><td>38.0</td><td>205.0</td><td>18.0</td><td>60.0</td><td>596.0</td><td>15.0</td><td>491.0</td><td>625.0</td><td>115.0</td><td>28.0</td><td>&hellip;</td><td>0.0</td><td>130.0</td><td>55.0</td><td>62.0</td><td>755.0</td><td>125.0</td><td>412.0</td><td>704.0</td><td>118.0</td><td>61.0</td><td>200.0</td><td>130.0</td><td>50.0</td><td>101.0</td><td>120.0</td><td>71.0</td><td>921.0</td><td>155.0</td><td>195.0</td><td>1271.0</td><td>190.0</td><td>60.0</td><td>30.0</td><td>488.0</td><td>5.0</td><td>45.0</td><td>10.0</td><td>89.0</td><td>598.0</td><td>105.0</td><td>47.0</td><td>699.0</td><td>65.0</td><td>145.0</td><td>68.0</td><td>80.0</td><td>0.0</td></tr><tr><td>&quot;T4930-80651&quot;</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>5.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>2.0</td><td>&hellip;</td><td>0.0</td><td>0.0</td><td>3.0</td><td>1.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>2.0</td><td>0.0</td><td>2.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>2.0</td><td>0.0</td><td>0.0</td><td>3.0</td><td>0.0</td><td>3.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>2.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;CE11-0319A&quot;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>&hellip;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;T4682-55393&quot;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>2.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>&hellip;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;3161C017&quot;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>&hellip;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>3.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr></tbody></table></div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T22:31:57.746646Z",
     "start_time": "2025-08-19T22:31:57.738386Z"
    }
   },
   "cell_type": "code",
   "source": [
    "part_numbers = aligned_df.get_column('oper_part_no')\n",
    "X_np = aligned_df.select(pl.all().exclude(\"oper_part_no\")).to_numpy()\n",
    "X_tensor = torch.tensor(X_np, dtype=torch.float32).unsqueeze(-1)  # shape (N, T, 1)"
   ],
   "id": "94471e84358d7128",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T22:32:20.566539Z",
     "start_time": "2025-08-19T22:31:57.777817Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = KShapeClusteringGPU(n_clusters=5, centroid_init = 'random', max_iter=100)\n",
    "model.fit(X_tensor)\n",
    "\n",
    "labels = model.labels_\n",
    "centroids = model.centroids_\n",
    "\n",
    "result = pl.DataFrame({\n",
    "    'oper_part_no': part_numbers,\n",
    "    'cluster_label': labels.astype(int)\n",
    "})\n",
    "\n",
    "result"
   ],
   "id": "1f09ef89e7d1a0c8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/igwanhyeong/PycharmProjects/data_research/models/clustering/k-shape/kshape_core_gpu.py:222: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(x, device = device, dtype = torch.float32)\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "The operator 'aten::_linalg_eigh.eigenvalues' is not currently implemented for the MPS device. If you want this op to be considered for addition please comment on https://github.com/pytorch/pytorch/issues/141287 and mention use-case, that resulted in missing op as well as commit hash e2d141dbde55c2a4370fac5165b0561b6af4798b. As a temporary fix, you can set the environment variable `PYTORCH_ENABLE_MPS_FALLBACK=1` to use the CPU as a fallback for this op. WARNING: this will be slower than running natively on MPS.",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNotImplementedError\u001B[39m                       Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[5]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m model = KShapeClusteringGPU(n_clusters=\u001B[32m5\u001B[39m, centroid_init = \u001B[33m'\u001B[39m\u001B[33mrandom\u001B[39m\u001B[33m'\u001B[39m, max_iter=\u001B[32m100\u001B[39m)\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_tensor\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m      4\u001B[39m labels = model.labels_\n\u001B[32m      5\u001B[39m centroids = model.centroids_\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/data_research/models/clustering/k-shape/kshape_core_gpu.py:184\u001B[39m, in \u001B[36mKShapeClusteringGPU.fit\u001B[39m\u001B[34m(self, X, y)\u001B[39m\n\u001B[32m    183\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mfit\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, y = \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[32m--> \u001B[39m\u001B[32m184\u001B[39m     clusters = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_fit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mn_clusters\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcentroid_init\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mmax_iter\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    185\u001B[39m     \u001B[38;5;28mself\u001B[39m.labels_ = np.zeros(X.shape[\u001B[32m0\u001B[39m])\n\u001B[32m    186\u001B[39m     \u001B[38;5;28mself\u001B[39m.centroids_ = torch.zeros(\u001B[38;5;28mself\u001B[39m.n_clusters, X.shape[\u001B[32m1\u001B[39m], X.shape[\u001B[32m2\u001B[39m], device = device, dtype = torch.float32)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/data_research/models/clustering/k-shape/kshape_core_gpu.py:223\u001B[39m, in \u001B[36mKShapeClusteringGPU._fit\u001B[39m\u001B[34m(self, x, k, centroid_init, max_iter)\u001B[39m\n\u001B[32m    221\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_fit\u001B[39m(\u001B[38;5;28mself\u001B[39m, x, k, centroid_init = \u001B[33m'\u001B[39m\u001B[33mzero\u001B[39m\u001B[33m'\u001B[39m, max_iter = \u001B[32m100\u001B[39m):\n\u001B[32m    222\u001B[39m     x = torch.tensor(x, device = device, dtype = torch.float32)\n\u001B[32m--> \u001B[39m\u001B[32m223\u001B[39m     idx, centroids = \u001B[43m_kshape\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mk\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcentroid_init\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_iter\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_iter\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    224\u001B[39m     clusters = []\n\u001B[32m    225\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m i, centroid \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(centroids):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/data_research/models/clustering/k-shape/kshape_core_gpu.py:137\u001B[39m, in \u001B[36m_kshape\u001B[39m\u001B[34m(x, k, centroid_init, max_iter)\u001B[39m\n\u001B[32m    135\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m j \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(k):\n\u001B[32m    136\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m d \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(x.shape[\u001B[32m2\u001B[39m]):\n\u001B[32m--> \u001B[39m\u001B[32m137\u001B[39m         centroids[j, :, d] = \u001B[43m_extract_shape\u001B[49m\u001B[43m(\u001B[49m\u001B[43midx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43munsqueeze\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43md\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m2\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43munsqueeze\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcentroids\u001B[49m\u001B[43m[\u001B[49m\u001B[43mj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43md\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    140\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m i, ts \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(x):\n\u001B[32m    141\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m c, ct \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(centroids):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/data_research/models/clustering/k-shape/kshape_core_gpu.py:107\u001B[39m, in \u001B[36m_extract_shape\u001B[39m\u001B[34m(idx, x, j, cur_center)\u001B[39m\n\u001B[32m    105\u001B[39m p = torch.eye(columns, device = device, dtype = torch.float32) - p \u001B[38;5;66;03m# Centering matrix\u001B[39;00m\n\u001B[32m    106\u001B[39m m = p.mm(s).mm(p)\n\u001B[32m--> \u001B[39m\u001B[32m107\u001B[39m _, vec = \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mlinalg\u001B[49m\u001B[43m.\u001B[49m\u001B[43meigh\u001B[49m\u001B[43m(\u001B[49m\u001B[43mm\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mUPLO\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mU\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m    108\u001B[39m centroid = vec[:, -\u001B[32m1\u001B[39m] \u001B[38;5;66;03m# Top eigen vector\u001B[39;00m\n\u001B[32m    110\u001B[39m \u001B[38;5;66;03m# Resolve direction ambiguity\u001B[39;00m\n",
      "\u001B[31mNotImplementedError\u001B[39m: The operator 'aten::_linalg_eigh.eigenvalues' is not currently implemented for the MPS device. If you want this op to be considered for addition please comment on https://github.com/pytorch/pytorch/issues/141287 and mention use-case, that resulted in missing op as well as commit hash e2d141dbde55c2a4370fac5165b0561b6af4798b. As a temporary fix, you can set the environment variable `PYTORCH_ENABLE_MPS_FALLBACK=1` to use the CPU as a fallback for this op. WARNING: this will be slower than running natively on MPS."
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "1358395305369a0f",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
