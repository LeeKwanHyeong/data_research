{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import sys\n",
    "\n",
    "import polars as pl\n",
    "import torch\n",
    "\n",
    "from data_loader.TimeSeriesModule import MultiPartDataModule\n",
    "from model_runner.train.titanl_train import TitanTrain\n",
    "from models.Titan.Titans import LMMModel\n",
    "import torch.nn as nn\n",
    "\n",
    "'''\n",
    "pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128\n",
    "https://developer.nvidia.com/cuda-12-8-0-download-archive\n",
    "'''\n",
    "\n",
    "MAC_DIR = '../data/'\n",
    "WINDOW_DIR = 'C:/Users/USER/PycharmProjects/research/data/'\n",
    "\n",
    "if sys.platform == 'win32':\n",
    "    DIR = WINDOW_DIR\n",
    "    print(torch.cuda.is_available())\n",
    "    print(torch.cuda.device_count())\n",
    "    print(torch.version.cuda)\n",
    "    print(torch.__version__)\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print(torch.__version__)\n",
    "else:\n",
    "    DIR = MAC_DIR"
   ],
   "id": "252fecffaf2ddff2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from models.Titan.common.configs import TitanConfigMonthly\n",
    "\n",
    "target_dyn_demand_monthly = pl.read_parquet(DIR + 'target_dyn_demand_monthly.parquet')\n",
    "cfg = TitanConfigMonthly()\n",
    "\n",
    "\n",
    "data_module = MultiPartDataModule(\n",
    "    df = target_dyn_demand_monthly,\n",
    "    config = cfg,\n",
    "    batch_size = 128,\n",
    "    val_ratio = 0.2,\n",
    "    is_running = False\n",
    ")\n",
    "\n",
    "plan_yyyymm = 202401\n",
    "train_loader = data_module.get_train_loader()\n",
    "val_loader = data_module.get_val_loader()\n",
    "anchor_loader = data_module.get_inference_loader_at_plan(\n",
    "    plan_dt = plan_yyyymm,\n",
    "    parts_filter = None,\n",
    "    fill_missing = 'ffill'\n",
    ")\n",
    "from utils.validation_utils import collect_indices\n",
    "\n",
    "fp_tr = collect_indices(train_loader)\n",
    "fp_va = collect_indices(val_loader)\n",
    "print(\"fp shapes:\", fp_tr.shape, fp_va.shape)\n",
    "print(\"approx equal:\", torch.allclose(fp_tr.mean(0), fp_va.mean(0)))"
   ],
   "id": "e35feceeba01f6a3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Model Training",
   "id": "4d9e69103a246da1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model = LMMModel(cfg)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr = 1e-3, weight_decay = 1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer = optimizer, T_max = 10)\n",
    "\n",
    "trained_model, tr_hist, va_hist = TitanTrain().train_model_with_tta(\n",
    "    model = model,\n",
    "    train_loader = train_loader,\n",
    "    val_loader = val_loader\n",
    ")"
   ],
   "id": "d73f1075197136cf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "xb, yb, *rest = next(iter(train_loader))\n",
    "print(\"y batch min/max:\", yb.min().item(), yb.max().item())\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    pred = model(xb.to(next(model.parameters()).device))\n",
    "pred_cpu = pred.detach().cpu()\n",
    "\n",
    "print(\"pred min/max:\", pred_cpu.min().item(), pred_cpu.max().item())\n",
    "\n",
    "xb, *rest = next(iter(anchor_loader))\n",
    "xb = xb.to(device)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    raw = model(xb)  # (B,H) or (B,Q,H)\n",
    "print(\"RAW on anchor min/max:\", raw.min().item(), raw.max().item())\n",
    "\n",
    "print(model.head)  # 또는 model\n",
    "for name, m in model.named_modules():\n",
    "    if isinstance(m, (nn.Sigmoid, nn.Tanh)):\n",
    "        print(\"Found bounded activation:\", name, m)"
   ],
   "id": "c1988781eecc9154"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Model Save",
   "id": "e0f39d05d057a728"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Full Save\n",
    "torch.save({\n",
    "    'model_state': trained_model.state_dict(),\n",
    "    'optimizer_state': optimizer.state_dict(),\n",
    "    'scheduler_state': scheduler.state_dict(),\n",
    "    'config': vars(cfg),\n",
    "    'train_loss_hist': tr_hist,\n",
    "    'val_loss_hist': va_hist\n",
    "}, DIR + 'fit/titan_20250922_ltb_full.pt')\n",
    "\n",
    "# only for weight\n",
    "# torch.save(model.state_dict(), DIR + f'titan_tta_20250922_l{cfg.lookback}_h_{cfg.horizon}.pt')"
   ],
   "id": "a29826d56ff2bd4c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Load Train Model",
   "id": "57887699c55a2dce"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# ------------------ Full Recall ------------------\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "ckpt = torch.load(DIR + 'fit/titan_20250922_ltb_full.pt', map_location = device)\n",
    "cfg = TitanConfigMonthly()\n",
    "model = LMMModel(cfg).to(device)\n",
    "model.load_state_dict(ckpt['model_state'])\n",
    "optimizer.load_state_dict(ckpt['optimizer_state'])\n",
    "scheduler.load_state_dict(ckpt['scheduler_state'])\n",
    "\n",
    "# ------------------ Weight Recall ------------------\n",
    "# ckpt_path = DIR + 'fit/titan_20250922_ltb_full.pt', map_location = device)\n",
    "# state = torch.load(ckpt_path, map_location = device)\n",
    "# model.load_state_dict(state)\n",
    "\n",
    "model.to(device).eval()"
   ],
   "id": "bc26e6aba70ce8c6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "3d461cb0ece1b64d",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
