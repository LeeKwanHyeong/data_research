{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import sys\n",
    "\n",
    "import polars as pl\n",
    "import torch\n",
    "\n",
    "from data_loader.TimeSeriesModule import MultiPartDataModule\n",
    "from training.config import TrainingConfig\n",
    "from training.model_trainers.total_train import run_total_train_monthly\n",
    "from utils.checkpoint import save_model_dict, load_model_dict\n",
    "from utils.plot_utils import plot_val_per_part, plot_120_months_many\n",
    "\n",
    "'''\n",
    "pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128\n",
    "https://developer.nvidia.com/cuda-12-8-0-download-archive\n",
    "'''\n",
    "\n",
    "MAC_DIR = '../data/'\n",
    "WINDOW_DIR = 'C:/Users/USER/PycharmProjects/research/data/'\n",
    "\n",
    "if sys.platform == 'win32':\n",
    "    DIR = WINDOW_DIR\n",
    "    print(torch.cuda.is_available())\n",
    "    print(torch.cuda.device_count())\n",
    "    print(torch.version.cuda)\n",
    "    print(torch.__version__)\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print(torch.__version__)\n",
    "else:\n",
    "    DIR = MAC_DIR"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T08:07:10.169698Z",
     "start_time": "2025-09-26T08:07:09.070700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "class DummyUsesExo(torch.nn.Module):\n",
    "    def __init__(self, H, exo_dim):\n",
    "        super().__init__()\n",
    "        self.H = H\n",
    "        self.w = torch.nn.Linear(exo_dim, 1, bias=False)\n",
    "    def forward(self, x, future_exo=None, mode=None):\n",
    "        if future_exo is None:\n",
    "            return torch.zeros(x.size(0), self.H, device=x.device)\n",
    "        return self.w(future_exo).squeeze(-1)  # (B,H,exo_dim) -> (B,H)\n",
    "\n",
    "B, L, C, H, exo_dim = 2, 24, 1, 12, 2\n",
    "x = torch.randn(B, L, C)\n",
    "\n",
    "def make_exo(offset):\n",
    "    t = torch.arange(offset, offset+H).float()\n",
    "    exo = torch.stack([torch.sin(2*torch.pi*t/12), torch.cos(2*torch.pi*t/12)], -1)\n",
    "    return exo.unsqueeze(0).expand(B, -1, -1)\n",
    "\n",
    "m = DummyUsesExo(H, exo_dim)\n",
    "from training.adapters import DefaultAdapter\n",
    "ad = DefaultAdapter()\n",
    "\n",
    "y1 = ad.forward(m, x, future_exo=make_exo(0), mode='train')\n",
    "y2 = ad.forward(m, x, future_exo=make_exo(3), mode='train')\n",
    "print(\"diff:\", (y1 - y2).abs().sum().item())  # 0보다 커야 정상\n"
   ],
   "id": "fe6699c5f5140687",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff: 18.067934036254883\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "target_dyn_demand_monthly = pl.read_parquet(DIR + 'target_dyn_demand_monthly.parquet')",
   "id": "2e4f705dccc25d11",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plan_yyyymm = 202305\n",
    "\n",
    "train_cfg = TrainingConfig()\n",
    "\n",
    "data_module = MultiPartDataModule(\n",
    "    target_dyn_demand_monthly,\n",
    "    train_cfg,\n",
    "    batch_size = 64,\n",
    "    val_ratio = 0.2,\n",
    "    is_running = False\n",
    ")\n",
    "train_loader = data_module.get_train_loader()\n",
    "val_loader = data_module.get_val_loader()"
   ],
   "id": "458546fab2f1ac1b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model_dict = run_total_train_monthly(train_loader, val_loader)",
   "id": "c5cf4896c51c94b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model_dict",
   "id": "9509f96cb01072de",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from models.PatchTST.common.configs import PatchTSTConfigMonthly\n",
    "from models.Titan.common.configs import TitanConfigMonthly\n",
    "from models.PatchMixer.common.configs import PatchMixerConfigMonthly\n",
    "\n",
    "save_dir = DIR + 'fit'\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "pm_config = PatchMixerConfigMonthly(\n",
    "        device = device,\n",
    "        loss_mode = 'quantile',\n",
    "        quantiles = (0.1, 0.5, 0.9)\n",
    "    )\n",
    "\n",
    "ti_config = TitanConfigMonthly(\n",
    "        device = device,\n",
    "        loss_mode = 'point',\n",
    "        point_loss = 'huber'\n",
    "    )\n",
    "\n",
    "pt_config = PatchTSTConfigMonthly(\n",
    "        device = device,\n",
    "        loss_mode = 'auto',\n",
    "        quantiles = (0.1, 0.5, 0.9)\n",
    "    )\n",
    "\n",
    "cfg_map = {\n",
    "    \"PatchMixer Base\": pm_config,\n",
    "    \"PatchMixer Quantile\": pm_config,\n",
    "    \"Titan Base\": ti_config,\n",
    "    \"Titan LMM\": ti_config,\n",
    "    \"Titan Seq2Seq\": ti_config,\n",
    "    \"PatchTST Base\": pt_config\n",
    "}\n",
    "\n",
    "builder_key_by_name = {\n",
    "  \"PatchMixer Base\": \"patchmixer_base\",\n",
    "  \"PatchMixer Quantile\": \"patchmixer_quantile\",\n",
    "  \"Titan Base\": \"titan_base\",\n",
    "  \"Titan LMM\": \"titan_lmm\",\n",
    "  \"Titan Seq2Seq\": \"titan_seq2seq\",\n",
    "  \"PatchTST Base\": \"patchtst_base\",\n",
    "}\n",
    "save_index = save_model_dict(model_dict, save_dir, cfg_by_name = cfg_map, builder_key_by_name=builder_key_by_name)\n",
    "\n",
    "# Load\n",
    "from models.model_builder import (\n",
    "    build_patch_mixer_base, build_patch_mixer_quantile,\n",
    "    build_titan_base, build_titan_lmm, build_titan_seq2seq,\n",
    "    build_patchTST_base\n",
    ")\n",
    "\n",
    "builders = {\n",
    "    \"patchmixer_base\": lambda cfg: build_patch_mixer_base(cfg or PatchMixerConfigMonthly()),\n",
    "    \"patchmixer_quantile\": lambda cfg: build_patch_mixer_quantile(cfg or PatchMixerConfigMonthly()),\n",
    "    \"titan_base\": lambda cfg: build_titan_base(cfg or TitanConfigMonthly()),\n",
    "    \"titan_lmm\": lambda cfg: build_titan_lmm(cfg or TitanConfigMonthly()),\n",
    "    \"titan_seq2seq\": lambda cfg: build_titan_seq2seq(cfg or TitanConfigMonthly()),\n",
    "    \"patchtst_base\": lambda cfg: build_patchTST_base(cfg or PatchTSTConfigMonthly()),\n",
    "}\n",
    "loaded = load_model_dict(save_dir, builders, device = device)\n",
    "\n",
    "plot_out = DIR + 'plot'\n",
    "plot_120_months_many(loaded, val_loader, device=device, use_truth=True,\n",
    "                     max_plots=100, show=True)"
   ],
   "id": "555c368f215381c2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "2486960dfa3fa119",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
